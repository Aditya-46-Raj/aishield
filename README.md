# AIShield â€“ Multiâ€‘Modal KYC Fraud Detection Engine

*A transparent, explainable, and deepfakeâ€‘resistant identity verification system.*

---

## ğŸŒ Overview

AIShield is a productionâ€‘ready, multiâ€‘modal KYC fraud detection engine designed to stop the latest wave of AIâ€‘generated identity attacksâ€”ranging from forged ID documents to deepfake selfie videos. Instead of relying on a single verification signal, AIShield analyzes **document forensics**, **biometric liveness**, **antiâ€‘spoof patterns**, and **faceâ€‘embedding similarity** before producing a final, explainable fraud score.

The system is built endâ€‘toâ€‘end with a **FastAPI backend**, a clean and intuitive **Streamlit UI**, and a compact but powerful collection of AI models. Every verification generates an **auditâ€‘ready case log** with heatmaps, SHAP explanations, and key metrics to support regulatory review.

This repository contains the complete implementation of AIShield used for the GHCI 2025 Hackathon submission.

---

## ğŸš€ Key Features

### **1. Hybrid Document Forgery Detection (ELA + CNN)**

* Error Level Analysis detects recompression artifacts and local tampering.
* EfficientNetâ€‘B0â€“based classifier identifies subtle visual inconsistencies.
* Final `doc_score` combines both signals.
* Heatmaps highlight manipulated regions.

### **2. Biometric Liveness & Antiâ€‘Spoofing**

* Extracts 5â€“10 frames from selfie video.
* Motion + blink cues using facial landmarks.
* Lightweight FFTâ€‘based antiâ€‘spoof model to catch screen replays & deepfakes.
* Outputs `liveness_score` and `deepfake_score`.

### **3. Face Embedding Matching**

* Uses highâ€‘dimensional facial embeddings to match ID photo to selfie.
* Robust against lighting changes and slight posture variations.

### **4. Fusion Risk Engine with Explainability**

* LightGBM model fuses all signals into a single fraud probability.
* SHAP explanations show contribution of each feature.

### **5. Admin Dashboard + Audit Logs**

* Each verification becomes a structured JSON case log.
* Inspect heatmaps, SHAP scores, detailed metrics.
* Download evidence for compliance.

---

## ğŸ—ï¸ Architecture

```
User â†’ Streamlit UI â†’ FastAPI Backend â†’
   [Document Forensics]    â†’ doc_score
   [Liveness Engine]       â†’ liveness_score
   [Embedding Matching]    â†’ embed_similarity
â†’ LightGBM Fusion â†’ Final Fraud Score + SHAP
â†’ Audit Log â†’ Admin Dashboard
```

---

## ğŸ“‚ Repository Structure

```
aishield/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                # FastAPI server
â”‚   â”œâ”€â”€ audit_logger.py       # Case logging
â”‚   â”œâ”€â”€ dataset/              # Clean/forged IDs
â”‚   â”œâ”€â”€ models/               # CNN + Fusion model
â”‚   â””â”€â”€ utils/                # ELA, liveness, embeddings
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                # Streamlit UI (User + Admin)
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml        # Optional container setup
â””â”€â”€ README.md                 # You are here
```

---

## ğŸ”§ Installation & Setup

### **1. Clone the Repository**

```
git clone https://github.com/Aditya-46-Raj/aishield
cd aishield
```

### **2. Run Backend (FastAPI)**

```
cd backend
pip install -r requirements.txt
uvicorn app:app --reload
```

Backend runs on: **[http://localhost:8000](http://localhost:8000)**

### **3. Run Frontend (Streamlit)**

```
cd frontend
pip install -r requirements.txt
streamlit run app.py
```

Frontend runs on: **[http://localhost:8501](http://localhost:8501)**

---

## ğŸ“Š How the Verification Pipeline Works

### **Step 1 â€” Document Upload**

* ELA image and difference map computed.
* CNN runs forgery classification.
* Combined: `doc_score`.

### **Step 2 â€” Video/Liveness Upload**

* Video â†’ frames â†’ motion analysis.
* Antiâ€‘spoof deepfake scoring.
* Combined: `liveness_score`.

### **Step 3 â€” Face Embedding Matching**

* ID photo â†” Selfie embeddings.
* Output: `embed_similarity`.

### **Step 4 â€” Fusion Model**

* Merges doc + liveness + embedding.
* Produces `fused_fraud_prob`.

### **Step 5 â€” Explainability & Logs**

* SHAP bar graph.
* ELA heatmap.
* Complete JSON case log.

---

## ğŸ“‘ Audit Logs

* Located in: `backend/logs/`
* Automatically generated at each verification.
* Contains:

  * Individual scores
  * SHAP contributions
  * Document heatmap path
  * Timestamps & case ID

A small README inside the logs folder explains its purpose.

---

## ğŸ–¥ï¸ Screenshots (To Be Added)

Add the following before final submission:

* Document Forgery Heatmap
* Liveness / Deepfake Result
* SHAP Explanation Plot
* Admin Dashboard View
* Final Combined Result Page

---

## ğŸ“¹ Demo Video

Link: **(Add your YouTube video link here)**

---

## ğŸ’¡ Why AIShield Stands Out

* Multiâ€‘modal analysis instead of singleâ€‘signal checks
* Transparent & explainable (SHAP, heatmaps, logs)
* Deepfakeâ€‘resistant liveness detection
* Realistic architecture built for scalability
* Clean UI + Admin console for compliance teams

---

## ğŸ“˜ License

This project is built solely for the GHCI 2025 Hackathon (Nonâ€‘commercial demonstration).

---

## ğŸ¤ Contributors

**Aditya Raj (Team 0AI)** â€“ Design, development, model integration, UI, backend, testing, and architecture.

AIShield represents a complete multiâ€‘modal approach to secure digital onboarding â€” combining transparency, technical rigor, and practical deployability.
